{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# AI Гид (solution by \"Улыбка Мона Лизы\")"
      ],
      "metadata": {
        "id": "9sVQDS1m0hjJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Сбор и подготовка данных"
      ],
      "metadata": {
        "id": "jP2XJiAB03kK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Импорты"
      ],
      "metadata": {
        "id": "bmrBIKNR8S2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain-mistralai"
      ],
      "metadata": {
        "id": "wXL6536n1PdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "MISTRAL_API_KEY = userdata.get('MISTRAL_API_KEY')"
      ],
      "metadata": {
        "id": "rwHOMUx51TVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import csv\n",
        "import os\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Optional\n",
        "import requests\n",
        "from langchain_mistralai import ChatMistralAI"
      ],
      "metadata": {
        "id": "-UyQkI9J1AtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Константы"
      ],
      "metadata": {
        "id": "jJBRVCMq8ZvT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "API_URL = \"https://ru.wikivoyage.org/w/api.php\"\n",
        "HEADERS = {\n",
        "    \"User-Agent\": \"TravelAIBot/1.0\"\n",
        "}"
      ],
      "metadata": {
        "id": "qE4PTn9E6yb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = Path(\"dataset\")\n",
        "RAW_FILE = DATA_DIR / \"wikivoyage_ru_raw.jsonl\"\n",
        "CLEAN_FILE = DATA_DIR / \"wikivoyage_ru_clean.jsonl\"\n",
        "FINAL_FILE = DATA_DIR / \"wikivoyage_ru_final.jsonl\"\n",
        "CSV_FILE = DATA_DIR / \"wikivoyage_ru_final.csv\"\n",
        "DATA_DIR.mkdir(exist_ok=True)"
      ],
      "metadata": {
        "id": "8qKYINuf1kSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LLM = ChatMistralAI(\n",
        "    model=\"mistral-small-latest\",\n",
        "    temperature=0.0,\n",
        "    mistral_api_key=MISTRAL_API_KEY\n",
        ")"
      ],
      "metadata": {
        "id": "jILPOGtW1nOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNn8_K1R0gY1"
      },
      "outputs": [],
      "source": [
        "PROMPT = \"\"\"Извлеки информацию ТОЛЬКО из переданного вики-текста статьи.\n",
        "НИЧЕГО НЕ ПРИДУМЫВАЙ и не добавляй из своих знаний.\n",
        "\n",
        "Если в тексте прямо и явно НЕ написано — ставь null.\n",
        "\n",
        "Верни ТОЛЬКО валидный JSON без каких-либо пояснений:\n",
        "\n",
        "{\n",
        "  \"country\": \"страна (или null)\",\n",
        "  \"city\": \"точное название города/региона/объекта (или null)\",\n",
        "  \"description\": \"краткое описание в 2–4 предложения на русском языке\",\n",
        "  \"attractions\": [\"названия достопримечательностей из текста\", \"...\"],\n",
        "  \"tips_for_traveler\": \"одним абзацем только то, что написано в статье про транспорт, визы, безопасность, деньги, здоровье и т.п. (или null, если таких сведений нет)\"\n",
        "}\n",
        "Обрабатывай только основной текст, игнорируй шаблоны, категории и служебную информацию.\n",
        "\n",
        "Вики-текст статьи:\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Вспомогательные функции"
      ],
      "metadata": {
        "id": "B4qh2yT68hyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def log(*args):\n",
        "    print(\"[*]\", *args)"
      ],
      "metadata": {
        "id": "R2C8JDFM16_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверка для фильтрации пустых страниц\n",
        "def is_redirect(wikitext: str):\n",
        "    return wikitext.strip().upper().startswith((\"#REDIRECT\", \"#ПЕРЕНАПРАВЛЕНИЕ\"))"
      ],
      "metadata": {
        "id": "jLCgetsB19-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def append_jsonl(item: Dict, path: Path):\n",
        "    with open(path, \"a\", encoding=\"utf-8\") as f:\n",
        "        f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")"
      ],
      "metadata": {
        "id": "YyMpc8xA1_lD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def api_get(params: dict):\n",
        "    r = requests.get(API_URL, params=params, headers=HEADERS, timeout=30)\n",
        "    r.raise_for_status()\n",
        "    return r.json()"
      ],
      "metadata": {
        "id": "dQ3ElbAM63in"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Получение содержимого страницы\n",
        "def fetch_wikitext(title: str):\n",
        "    data = api_get({\n",
        "        \"action\": \"query\",\n",
        "        \"format\": \"json\",\n",
        "        \"prop\": \"revisions\",\n",
        "        \"rvprop\": \"content\",\n",
        "        \"rvslots\": \"main\",\n",
        "        \"titles\": title\n",
        "    })\n",
        "    page = next(iter(data[\"query\"][\"pages\"].values()))\n",
        "    return page[\"revisions\"][0][\"slots\"][\"main\"][\"*\"] if \"revisions\" in page else None"
      ],
      "metadata": {
        "id": "_6coaAqu7MPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверка существования страницы в файле результата\n",
        "def is_already_saved(title: str, path: str):\n",
        "    if not os.path.exists(path):\n",
        "        return False\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        return any(json.loads(line).get(\"title\") == title for line in f)"
      ],
      "metadata": {
        "id": "xZVf7U1k7N6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Получение списка страниц\n",
        "def get_all_pages():\n",
        "    pages = []\n",
        "    cont = None\n",
        "    print(\"Получаем список всех страниц...\")\n",
        "    while True:\n",
        "        params = {\n",
        "            \"action\": \"query\",\n",
        "            \"format\": \"json\",\n",
        "            \"list\": \"allpages\",\n",
        "            \"aplimit\": \"max\",\n",
        "            \"apnamespace\": \"0\"\n",
        "        }\n",
        "        if cont:\n",
        "            params[\"apcontinue\"] = cont\n",
        "\n",
        "        r = requests.get(API_URL, params=params, headers=HEADERS, timeout=30)\n",
        "        r.raise_for_status()\n",
        "        data = r.json()\n",
        "        pages.extend(data[\"query\"][\"allpages\"])\n",
        "\n",
        "        cont = data.get(\"continue\", {}).get(\"apcontinue\")\n",
        "        if not cont:\n",
        "            break\n",
        "        time.sleep(0.2)\n",
        "\n",
        "    print(f\"Найдено страниц: {len(pages)}\")\n",
        "    return [page['title'] for page in pages]"
      ],
      "metadata": {
        "id": "Wo-fxX0V7EED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Сохранение списка страниц"
      ],
      "metadata": {
        "id": "DLzxBfBxBOAw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titles_file = \"dataset/titles_cache.txt\"\n",
        "if os.path.exists(titles_file):\n",
        "    titles = [line.strip() for line in open(titles_file, \"r\", encoding=\"utf-8\")]\n",
        "    print(\"Список существует локально\")\n",
        "else:\n",
        "    titles = get_all_pages()\n",
        "    with open(titles_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        for t in titles:\n",
        "            f.write(t + \"\\n\")\n",
        "    print(f\"Список сохранён в {titles_file}\")"
      ],
      "metadata": {
        "id": "UbhwJ7bb3o7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "008c1773-58b1-4761-f16a-2684d9e46470"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Список существует локально\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Скачивание содержимого"
      ],
      "metadata": {
        "id": "MKP67H6ZBRP6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_wikitext(titles: list, output_file: Path):\n",
        "\n",
        "    print(f\"Скачивание содержимого {len(titles)} статей...\")\n",
        "    saved = 0\n",
        "\n",
        "    # Получаем список уже обработанных заголовков\n",
        "    processed_titles = set()\n",
        "    if os.path.exists(output_file):\n",
        "        with open(output_file, \"r\", encoding=\"utf-8\") as f:\n",
        "            for line in f:\n",
        "                try:\n",
        "                    data = json.loads(line.strip())\n",
        "                    processed_titles.add(data[\"title\"])\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "    # Фильтруем только те заголовки, которые еще не обработаны\n",
        "    titles_to_process = [title for title in titles if title not in processed_titles]\n",
        "\n",
        "    if not titles_to_process:\n",
        "        print(f\"Все статьи уже скачаны в {output_file}\")\n",
        "        return\n",
        "\n",
        "    with open(output_file, \"a\", encoding=\"utf-8\") as f:\n",
        "        with tqdm(titles_to_process, desc=\"Скачивание\") as pbar:\n",
        "            for title in pbar:\n",
        "                text = fetch_wikitext(title)\n",
        "                if text:\n",
        "                    record = {\n",
        "                        \"title\": title,\n",
        "                        \"url\": f\"https://ru.wikivoyage.org/wiki/{title.replace(' ', '_')}\",\n",
        "                        \"wikitext\": text\n",
        "                    }\n",
        "                    f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
        "                    saved += 1\n",
        "\n",
        "                time.sleep(0.33)\n",
        "\n",
        "    print(f\"Готово: {output_file} (+{saved} новых)\")"
      ],
      "metadata": {
        "id": "new-download-function"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "download_wikitext(titles, RAW_FILE)"
      ],
      "metadata": {
        "id": "48SrCT0u7g-0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe7345c1-f1bb-4d60-afcc-beb6e263d513"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Скачивание содержимого 7887 статей...\n",
            "Все статьи уже скачаны в dataset/wikivoyage_ru_raw.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Очистка данных"
      ],
      "metadata": {
        "id": "el0k7ipe9acJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if RAW_FILE.exists():\n",
        "    print(f\"Содержимое файла {RAW_FILE.name} (первые 5 строк):\")\n",
        "    with open(RAW_FILE, \"r\", encoding=\"utf-8\") as f:\n",
        "        for i, line in enumerate(f):\n",
        "            if i >= 5:\n",
        "                break\n",
        "            print(line.strip())\n",
        "else:\n",
        "    print(f\"Файл {RAW_FILE.name} не найден. Убедитесь, что он был создан на предыдущих этапах.\")"
      ],
      "metadata": {
        "id": "UTHrIpak9tkB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72a30b48-5a66-493a-c0fa-58a48a6a44b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Содержимое файла wikivoyage_ru_raw.jsonl (первые 5 строк):\n",
            "{\"title\": \"7+2\", \"url\": \"https://ru.wikivoyage.org/wiki/7+2\", \"wikitext\": \"#REDIRECT [[Project:Географическая иерархия#Деление на географические единицы]]\"}\n",
            "{\"title\": \"7 2\", \"url\": \"https://ru.wikivoyage.org/wiki/7_2\", \"wikitext\": \"#REDIRECT [[Project:Географическая_иерархия#Деление на географические единицы]]\"}\n",
            "{\"title\": \"Main Page\", \"url\": \"https://ru.wikivoyage.org/wiki/Main_Page\", \"wikitext\": \"#перенаправление [[Заглавная страница]]\"}\n",
            "{\"title\": \"WLE\", \"url\": \"https://ru.wikivoyage.org/wiki/WLE\", \"wikitext\": \"#REDIRECT[[Wikivoyage:Вики любит Землю]]\"}\n",
            "{\"title\": \"WLM\", \"url\": \"https://ru.wikivoyage.org/wiki/WLM\", \"wikitext\": \"#REDIRECT[[Wikivoyage:Вики любит памятники]]\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Удаление редиректов\n",
        "def remove_redirects():\n",
        "    if CLEAN_FILE.exists():\n",
        "        log(f\"{CLEAN_FILE.name} уже существует, пропускаем очистку\")\n",
        "        return\n",
        "\n",
        "    log(\"Удаляем редиректы...\")\n",
        "    clean_count = redirect_count = 0\n",
        "\n",
        "    with open(RAW_FILE, \"r\", encoding=\"utf-8\") as src, \\\n",
        "         open(CLEAN_FILE, \"w\", encoding=\"utf-8\") as dst:\n",
        "        for line in src:\n",
        "            data = json.loads(line)\n",
        "            if is_redirect(data[\"wikitext\"]):\n",
        "                redirect_count += 1\n",
        "            else:\n",
        "                dst.write(line)\n",
        "                clean_count += 1\n",
        "\n",
        "    log(f\"\"\"Оставлено: {clean_count}, удалено строк:\n",
        "    {redirect_count}. Итоговый файл - {CLEAN_FILE}\"\"\")\n"
      ],
      "metadata": {
        "id": "WGcDo_5H2GQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remove_redirects()"
      ],
      "metadata": {
        "id": "nOOnEUHlA0oL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cb193f9-86b9-460f-b49a-aaed280a192e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*] wikivoyage_ru_clean.jsonl уже существует, пропускаем очистку\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Извлечение признаков для табличных данных (Mistral API)"
      ],
      "metadata": {
        "id": "uxGprVh9-QPB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для итоговой структуры данных для RAG выбраны признаки:\n",
        "\n",
        "- title/заголовок страницы\n",
        "- country/страна\n",
        "- city/город\n",
        "- attractions/интересные места\n",
        "- description/описание\n",
        "- tips for traveler/советы путешественникам\n",
        "\n",
        "и служебное поле url"
      ],
      "metadata": {
        "id": "lteF12GL-xYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверка обработанных строк\n",
        "def get_processed_titles():\n",
        "    titles = set()\n",
        "    if FINAL_FILE.exists():\n",
        "        with open(FINAL_FILE, \"r\", encoding=\"utf-8\") as f:\n",
        "            for line in f:\n",
        "                try:\n",
        "                    titles.add(json.loads(line)[\"title\"])\n",
        "                except:\n",
        "                    pass\n",
        "    return titles"
      ],
      "metadata": {
        "id": "iZGDJeKh_N3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Извлечение признаков через Mistral\n",
        "def extract_features():\n",
        "    from tqdm import tqdm\n",
        "\n",
        "    # Читаем все title, которые уже есть в результате\n",
        "    processed_titles = set()\n",
        "    if open(FINAL_FILE, \"a+\", encoding=\"utf-8\").tell() > 0:  # если файл не пустой\n",
        "        with open(FINAL_FILE, \"r\", encoding=\"utf-8\") as f:\n",
        "            for line in f:\n",
        "                if line.strip():\n",
        "                    data = json.loads(line)\n",
        "                    processed_titles.add(data.get(\"title\"))\n",
        "\n",
        "    print(f\"Уже обработано статей: {len(processed_titles)}\")\n",
        "\n",
        "    # Открываем исходный файл и ищем недостающие\n",
        "    missing = []\n",
        "    with open(CLEAN_FILE, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            data = json.loads(line)\n",
        "            if data[\"title\"] not in processed_titles:\n",
        "                missing.append(data)\n",
        "\n",
        "    print(f\"Найдено недостающих/ошибочных: {len(missing)}\")\n",
        "\n",
        "    if not missing:\n",
        "        print(\"Всё уже обработано! Можно делать CSV.\")\n",
        "    else:\n",
        "        print(\"Обработка недостающих через Mistral...\\n\")\n",
        "\n",
        "        with open(FINAL_FILE, \"a\", encoding=\"utf-8\") as outfile:\n",
        "            with tqdm(missing, desc=\"Обработка статей\", unit=\"стран\") as pbar:\n",
        "                for item in pbar:\n",
        "                    title = item[\"title\"]\n",
        "                    wikitext = item[\"wikitext\"]\n",
        "\n",
        "                    # pbar.set_postfix({\"статья\": title[:30] + \"...\" if len(title) > 30 else title})\n",
        "\n",
        "                    for attempt in range(5):\n",
        "                        try:\n",
        "                            response = LLM.invoke(\n",
        "                                [\n",
        "                                    (\"system\", PROMPT),\n",
        "                                    (\"user\", wikitext[:28000])\n",
        "                                ],\n",
        "                                response_format={\"type\": \"json_object\"}\n",
        "                            )\n",
        "\n",
        "                            result = json.loads(response.content)\n",
        "                            result[\"title\"] = title\n",
        "                            result[\"url\"] = item[\"url\"]\n",
        "\n",
        "                            outfile.write(json.dumps(result, ensure_ascii=False) + \"\\n\")\n",
        "                            outfile.flush()\n",
        "                            break\n",
        "\n",
        "                        except Exception as e:\n",
        "                            # if \"429\" in str(e) or \"rate limit\" in str(e).lower():\n",
        "                            #     wait = 5 * (attempt + 1)\n",
        "                            #     pbar.write(f\" → 429, ждём {wait} сек...\")\n",
        "                            #     time.sleep(wait)\n",
        "                            # else:\n",
        "                            # pbar.write(f\"Ошибка для '{title}': {e}\")\n",
        "                            break\n",
        "                    else:\n",
        "                        pbar.write(f\"Пропущено после 5 попыток: '{title}'\")\n",
        "\n",
        "                    time.sleep(1)\n",
        "\n",
        "        print(f\"\\nРасчет завершён!\")"
      ],
      "metadata": {
        "id": "HiCX1v252J1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract_features()"
      ],
      "metadata": {
        "id": "6-TXZH0jA6bS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7198b0e-4c36-4978-a344-af0315cb6e1d"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Уже обработано статей: 6918\n",
            "Найдено недостающих/ошибочных: 9\n",
            "Обработка недостающих через Mistral...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Обработка статей:  78%|███████▊  | 7/9 [00:59<00:14,  7.29s/стран]WARNING:langchain_core.language_models.llms:Retrying langchain_mistralai.chat_models.ChatMistralAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ReadTimeout: The read operation timed out.\n",
            "Обработка статей: 100%|██████████| 9/9 [03:13<00:00, 21.51s/стран]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Расчет завершён!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Конвертация результата в csv"
      ],
      "metadata": {
        "id": "RRpxT2N1A8O6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def json_to_csv():\n",
        "    if CSV_FILE.exists():\n",
        "        log(f\"{CSV_FILE.name} уже существует\")\n",
        "        return\n",
        "\n",
        "    if not FINAL_FILE.exists():\n",
        "        log(\"Нет финального json\")\n",
        "        return\n",
        "\n",
        "    log(\"Создание CSV...\")\n",
        "\n",
        "    with open(FINAL_FILE, \"r\", encoding=\"utf-8\") as infile, \\\n",
        "         open(CSV_FILE, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
        "\n",
        "        fieldnames = [\"title\", \"country\", \"city\", \"description\", \"attractions\", \"tips_for_traveler\", \"url\"]\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "\n",
        "        total = sum(1 for _ in open(FINAL_FILE, \"r\", encoding=\"utf-8\"))\n",
        "        for i, line in enumerate(infile):\n",
        "            data = json.loads(line.strip())\n",
        "\n",
        "            attractions_str = \"; \".join(data.get(\"attractions\") or [])\n",
        "\n",
        "            row = {\n",
        "                \"title\": data.get(\"title\", \"\"),\n",
        "                \"country\": data.get(\"country\", \"\"),\n",
        "                \"city\": data.get(\"city\", \"\"),\n",
        "                \"description\": data.get(\"description\", \"\"),\n",
        "                \"attractions\": attractions_str,\n",
        "                \"tips_for_traveler\": data.get(\"tips_for_traveler\", \"\"),\n",
        "                \"url\": data.get(\"url\", \"\")\n",
        "            }\n",
        "            writer.writerow(row)\n",
        "\n",
        "            if (i + 1) % 200 == 0 or (i + 1) == total:\n",
        "                log(f\"Обработано {i + 1}/{total}\")\n",
        "\n",
        "    log(f\"Итоговый CSV: {CSV_FILE}\")"
      ],
      "metadata": {
        "id": "Afr1GHCY2Nyq"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json_to_csv()"
      ],
      "metadata": {
        "id": "uFs_A0C5A-aR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abb58c68-533f-4ec5-dcc0-a9e0b6c1322e"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*] Создание CSV...\n",
            "[*] Обработано 200/6919\n",
            "[*] Обработано 400/6919\n",
            "[*] Обработано 600/6919\n",
            "[*] Обработано 800/6919\n",
            "[*] Обработано 1000/6919\n",
            "[*] Обработано 1200/6919\n",
            "[*] Обработано 1400/6919\n",
            "[*] Обработано 1600/6919\n",
            "[*] Обработано 1800/6919\n",
            "[*] Обработано 2000/6919\n",
            "[*] Обработано 2200/6919\n",
            "[*] Обработано 2400/6919\n",
            "[*] Обработано 2600/6919\n",
            "[*] Обработано 2800/6919\n",
            "[*] Обработано 3000/6919\n",
            "[*] Обработано 3200/6919\n",
            "[*] Обработано 3400/6919\n",
            "[*] Обработано 3600/6919\n",
            "[*] Обработано 3800/6919\n",
            "[*] Обработано 4000/6919\n",
            "[*] Обработано 4200/6919\n",
            "[*] Обработано 4400/6919\n",
            "[*] Обработано 4600/6919\n",
            "[*] Обработано 4800/6919\n",
            "[*] Обработано 5000/6919\n",
            "[*] Обработано 5200/6919\n",
            "[*] Обработано 5400/6919\n",
            "[*] Обработано 5600/6919\n",
            "[*] Обработано 5800/6919\n",
            "[*] Обработано 6000/6919\n",
            "[*] Обработано 6200/6919\n",
            "[*] Обработано 6400/6919\n",
            "[*] Обработано 6600/6919\n",
            "[*] Обработано 6800/6919\n",
            "[*] Обработано 6919/6919\n",
            "[*] Итоговый CSV: dataset/wikivoyage_ru_final.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log(\"Данные находятся в папке dataset:\")\n",
        "log(\"wikivoyage_ru_final.jsonl\")\n",
        "log(\"wikivoyage_ru_final.csv\")"
      ],
      "metadata": {
        "id": "dpfohW8s2YGR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "545532b6-df18-4230-d51f-90a92eaeece7"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*] Данные находятся в папке dataset:\n",
            "[*] wikivoyage_ru_final.jsonl\n",
            "[*] wikivoyage_ru_final.csv\n"
          ]
        }
      ]
    }
  ]
}